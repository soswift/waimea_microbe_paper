ids <- metadata[[ID_column]]
metadata[, standardID := ids]
}
## make_pa(): converts a list to presence absence.
# Use lapply to convert a full OTU abundance table to presence absence data
make_pa <- function(Col) {
Col[Col != 0] <- 1
return(Col)
}
## gev_value(): conditionally replaces numeric value in list with numeric value from another list
get_value <- function(Val1, Val2){
New_Val <- ifelse(Val1 == 0, NA, Val2)
return(New_Val)
}
## sub_by_samples(): subsets an OTU table to match a vector of sample names.
# Assumes that OTU table columns are samples, rows are otus.
# If a column of OTU names should kept, indicate the column name.
sub_by_samples <- function(samples, otu_table, OTU_name_column = NA) {
if(is.na(OTU_name_column)){
# No OTU name column present
# subset columns by selected sample names
new_otu  <- otu_table[ , ..samples]
# remove OTUs with rowSums that = 0
new_otu[, Sums := rowSums(.SD)]
} else {
# OTU name column present, add it to the vector of sample names
samples <- c(OTU_name_column, samples)
# subset columns by selected sample names, preserving OTU names
new_otu  <- otu_table[ , ..samples]
# remove OTUs with rowSums that = 0, exlcuding OTU name column
new_otu[, Sums := rowSums(.SD), .SDcols = !OTU_name_column]
}
new_otu <- new_otu[Sums != 0, .SD, .SDcols = !"Sums"]
return(new_otu)
}
## count_spread(): Based on a grouping column in the metadata, count the total number of groups an OTU is in.
count_spread <-function(otu_table, metadata_table, group_column, key_column = "standardID", OTU_name_column = "OTU_ID"){
# copy data.table
otus_merge <- copy(otu_table)
# create vector of metadata columns that will be used for aggregating
meta_cols <- c(group_column, key_column)
# transpose OTU table so samples are rows and OTUs are columns
otus_merge <- transpose(otus_merge, keep.names = key_column, make.names = OTU_name_column)
# add grouping column to OTU table
otus_merge <- merge(otus_merge, metadata_table[, ..meta_cols], by = key_column)
# generate vector of OTU data columns, excluding the metadata columns
otu_cols <- colnames(otus_merge)
otu_cols <- otu_cols[!(otu_cols %in% meta_cols)]
# sum OTU counts by group
otus_merge <- otus_merge[, lapply(.SD, sum), by = group_column, .SDcols = otu_cols]
# convert summed counts to presence/absence
otus_merge[, (otu_cols) :=  lapply(.SD, make_pa ), .SDcols = otu_cols]
# count how many groups each OTU is in
counts <- colSums(otus_merge[, ..otu_cols])
# return OTU names and counts as a data.table
result <- data.table(OTU_ID = names(counts), group_count = counts)
return(result)
}
## get_geographic_range(): Calculate the geographic range of each OTU based on latitude or longitude.
get_geographic_range <-function(otu_table, metadata_table, coordinate_column, key_column = "standardID", OTU_name_column = "OTU_ID"){
# copy metadata table prior to editing
meta_merge <- copy(metadata_table)
# copy coordinates to new column 'coords', convert to numeric, drop NA values
suppressWarnings(meta_merge[ , coords := lapply( .SD, as.numeric ), .SDcols = coordinate_column])
meta_merge <- meta_merge[!( is.na( coords ) )]
# add 90 to all coordinate values to account for negative values
meta_merge[ , coords := coords + 90]
# convert to matrix
otus_mat <- as.matrix(otu_table, rownames = OTU_name_column)
# arrange to match metadata
otus_mat <- otus_mat[, meta_merge[[key_column]]]
# remove any empty OTUs
otus_mat <- otus_mat[ rowSums(otus_mat) != 0,]
# transform positive OTU counts to coordinate value
otus_mat <- apply( otus_mat, 1, FUN = get_value, Val2 = meta_merge$coords)
# calculate minimum and maximum coordinate values for each OTU column
min_coord <-colMins(otus_mat, na.rm = T)
max_coord <- colMaxs(otus_mat, na.rm = T)
range <- max_coord - min_coord
# return data.table
ranges <- data.table(OTU_ID =  colnames(otus_mat),
min_coord = min_coord,
max_coord = max_coord,
range = range)
return(ranges)
}
# Define Inputs ----------
# Toy data version
otu_file  <- "../../toy_data/toy_data/toy_emp_data.csv"
meta_file <- "../../toy_data/toy_data/toy_emp_metadata.csv"
# full data version
# Read in ----------
# full data version
# all_otus <- fread(otu_file)
# colnames(all_otus)[1] <- "OTU_ID"
#
# all_meta <- fread(meta_file)
# colnames(emp_meta)[1] <- "SampleID"
all_otus <- fread(otu_file)
all_meta <- fread(meta_file)
# set standard ID for meta
all_meta <- set_standardID(all_meta, "SampleID")
# Subset waimea samples
wai_meta <- all_meta[site_type == "Core Waimea"]
wai_otu <- sub_by_samples(samples = wai_meta$standardID,  otu_table = all_otus, OTU_name_column = "OTU_ID")
# Correlate ----------
wai_otu[1:5,1:5]
# for each OTU, count the number of sample types in which it occurs
sample_type_spread <- count_spread(
otu_table = wai_otu,
metadata_table = wai_meta,
group_column = "sample_type"
)
# for each OTU, calculate the geographic range in which it occurs
geographic_range <- get_geographic_range(otu_table = all_otus,
metadata_table = all_meta,
coordinate_column = "latitude_deg")
# merge range and spread data
range_dat <- merge(sample_type_spread, geographic_range, by = "OTU_ID")
# calculate linear model
range_mod <- lm( range ~ group_count, data = range_dat)
# run anova
range_anova <- anova(range_mod)
# predict confidence intervals
conf_int <- predict(range_mod, interval = "confidence", level = 0.95)
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_point(size = 2) +
labs(title = "Distribution Across Sample Types Predicts Globabl Range",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
# save plot
ggsave(filename = "sample_range_correlation.pdf", p)
# save data
saveRDS(list(range_dat, range_mod, range_anova, conf_int), "sample_range_correlation.rds")
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_point(size = 2) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3], color = "blue"), , fill = "blue", alpha = 0.2)
p
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_point(size = 2) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3], color = "blue"),  fill = "blue", alpha = 0.2)
p
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_point(size = 2) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
theme_set(theme_bw())
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_point(size = 2) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_point(size = 2) +
geom_jitter()+
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_jitter()+
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_jitter(width = 0.1, height = 0.1)+
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_point()+
#geom_jitter(width = 0.1, height = 0.1)+
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
?scale_x_continuous
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_jitter(width = 0.1, height = 0.1)+
scale_x_continuous(breaks = seq_along(max(group_count)))
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_jitter(width = 0.1, height = 0.1)+
scale_x_continuous(breaks = seq_along(max(range_dat$group_count)))
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_jitter(width = 0.1, height = 0.1)+
scale_x_continuous(breaks = seq_along( max( range_dat$group_count) ) )+
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
range_dat$group_count
max(range_dat$group_count)
seq_along( max( range_dat$group_count)
)
seq_along(10)
seq
seq(1:10)
?seq
seq_len(10)
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_jitter(width = 0.1, height = 0.1)+
scale_x_continuous(breaks = seq_len( max( range_dat$group_count) ) )+
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_jitter(width = 0.1, height = 1)+
scale_x_continuous(breaks = seq_len( max( range_dat$group_count) ) )+
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
geom_jitter(width = 0.2, height = 3)+
scale_x_continuous(breaks = seq_len( max( range_dat$group_count) ) )+
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) )+
labs(color = "Latitude Range", x = "Number of Sample Types", y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C")+
geom_abline(slope = coefficients(range_mod)[2], intercept = coefficients(range_mod)[1])+
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]), color = "blue", fill = "blue", alpha = 0.2)
p
?geom_point
# Global 16S - Sample Spread Distance Corellation - R Script
# Document Summary:
# This script corellates the number of samples an OTU is found in with it's global geographic range
# Written as a script to run on HPC.
library(data.table)
library(ggplot2)
library(matrixStats)
# set ggplot theme
theme_set(theme_bw())
# Define Functions ----------
## set_standardID(): Identify the metadata column that contains sample names
# In all other functions, OTUs and metadata will always be linked using column standardID
set_standardID <- function(metadata, ID_column){
ids <- metadata[[ID_column]]
metadata[, standardID := ids]
}
## make_pa(): converts a list to presence absence.
# Use lapply to convert a full OTU abundance table to presence absence data
make_pa <- function(Col) {
Col[Col != 0] <- 1
return(Col)
}
## gev_value(): conditionally replaces numeric value in list with numeric value from another list
get_value <- function(Val1, Val2){
New_Val <- ifelse(Val1 == 0, NA, Val2)
return(New_Val)
}
## sub_by_samples(): subsets an OTU table to match a vector of sample names.
# Assumes that OTU table columns are samples, rows are otus.
# If a column of OTU names should kept, indicate the column name.
sub_by_samples <- function(samples, otu_table, OTU_name_column = NA) {
if(is.na(OTU_name_column)){
# No OTU name column present
# subset columns by selected sample names
new_otu  <- otu_table[ , ..samples]
# remove OTUs with rowSums that = 0
new_otu[, Sums := rowSums(.SD)]
} else {
# OTU name column present, add it to the vector of sample names
samples <- c(OTU_name_column, samples)
# subset columns by selected sample names, preserving OTU names
new_otu  <- otu_table[ , ..samples]
# remove OTUs with rowSums that = 0, exlcuding OTU name column
new_otu[, Sums := rowSums(.SD), .SDcols = !OTU_name_column]
}
new_otu <- new_otu[Sums != 0, .SD, .SDcols = !"Sums"]
return(new_otu)
}
## count_spread(): Based on a grouping column in the metadata, count the total number of groups an OTU is in.
count_spread <-function(otu_table, metadata_table, group_column, key_column = "standardID", OTU_name_column = "OTU_ID"){
# copy data.table
otus_merge <- copy(otu_table)
# create vector of metadata columns that will be used for aggregating
meta_cols <- c(group_column, key_column)
# transpose OTU table so samples are rows and OTUs are columns
otus_merge <- transpose(otus_merge, keep.names = key_column, make.names = OTU_name_column)
# add grouping column to OTU table
otus_merge <- merge(otus_merge, metadata_table[, ..meta_cols], by = key_column)
# generate vector of OTU data columns, excluding the metadata columns
otu_cols <- colnames(otus_merge)
otu_cols <- otu_cols[!(otu_cols %in% meta_cols)]
# sum OTU counts by group
otus_merge <- otus_merge[, lapply(.SD, sum), by = group_column, .SDcols = otu_cols]
# convert summed counts to presence/absence
otus_merge[, (otu_cols) :=  lapply(.SD, make_pa ), .SDcols = otu_cols]
# count how many groups each OTU is in
counts <- colSums(otus_merge[, ..otu_cols])
# return OTU names and counts as a data.table
result <- data.table(OTU_ID = names(counts), group_count = counts)
return(result)
}
## get_geographic_range(): Calculate the geographic range of each OTU based on latitude or longitude.
get_geographic_range <-function(otu_table, metadata_table, coordinate_column, key_column = "standardID", OTU_name_column = "OTU_ID"){
# copy metadata table prior to editing
meta_merge <- copy(metadata_table)
# copy coordinates to new column 'coords', convert to numeric, drop NA values
suppressWarnings(meta_merge[ , coords := lapply( .SD, as.numeric ), .SDcols = coordinate_column])
meta_merge <- meta_merge[!( is.na( coords ) )]
# add 90 to all coordinate values to account for negative values
meta_merge[ , coords := coords + 90]
# convert to matrix
otus_mat <- as.matrix(otu_table, rownames = OTU_name_column)
# arrange to match metadata
otus_mat <- otus_mat[, meta_merge[[key_column]]]
# remove any empty OTUs
otus_mat <- otus_mat[ rowSums(otus_mat) != 0,]
# transform positive OTU counts to coordinate value
otus_mat <- apply( otus_mat, 1, FUN = get_value, Val2 = meta_merge$coords)
# calculate minimum and maximum coordinate values for each OTU column
min_coord <-colMins(otus_mat, na.rm = T)
max_coord <- colMaxs(otus_mat, na.rm = T)
range <- max_coord - min_coord
# return data.table
ranges <- data.table(OTU_ID =  colnames(otus_mat),
min_coord = min_coord,
max_coord = max_coord,
range = range)
return(ranges)
}
# Define Inputs ----------
# Toy data version
otu_file  <- "../../toy_data/toy_data/toy_emp_data.csv"
meta_file <- "../../toy_data/toy_data/toy_emp_metadata.csv"
# full data version
# Read in ----------
# full data version
# all_otus <- fread(otu_file)
# colnames(all_otus)[1] <- "OTU_ID"
#
# all_meta <- fread(meta_file)
# colnames(emp_meta)[1] <- "SampleID"
all_otus <- fread(otu_file)
all_meta <- fread(meta_file)
# set standard ID for meta
all_meta <- set_standardID(all_meta, "SampleID")
# Subset waimea samples
wai_meta <- all_meta[site_type == "Core Waimea"]
wai_otu <- sub_by_samples(samples = wai_meta$standardID,  otu_table = all_otus, OTU_name_column = "OTU_ID")
# Correlate ----------
wai_otu[1:5,1:5]
# for each OTU, count the number of sample types in which it occurs
sample_type_spread <- count_spread(
otu_table = wai_otu,
metadata_table = wai_meta,
group_column = "sample_type"
)
# for each OTU, calculate the geographic range in which it occurs
geographic_range <- get_geographic_range(otu_table = all_otus,
metadata_table = all_meta,
coordinate_column = "latitude_deg")
# merge range and spread data
range_dat <- merge(sample_type_spread, geographic_range, by = "OTU_ID")
# calculate linear model
range_mod <- lm( range ~ group_count, data = range_dat)
# run anova
range_anova <- anova(range_mod)
# predict confidence intervals
conf_int <- predict(range_mod, interval = "confidence", level = 0.95)
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
# points
geom_jitter(width = 0.2, height = 3) +
# scales and labels
scale_x_continuous(breaks = seq_len( max( range_dat$group_count) ) ) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) ) +
labs(color = "Latitude Range",
x = "Number of Sample Types",
y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C") +
# trend line and confidence interval
geom_abline(slope = coefficients(range_mod)[2],
intercept = coefficients(range_mod)[1]) +
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]),
color = "blue", fill = "blue", alpha = 0.2)
# save plot
ggsave(filename = "sample_range_correlation.pdf", p)
# save data
saveRDS(list(range_dat, range_mod, range_anova, conf_int), "sample_range_correlation.rds")
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
# points
geom_jitter(width = 0.2, height = 3) +
# scales and labels
scale_x_continuous(breaks = NULL) ) ) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) ) +
labs(color = "Latitude Range",
x = "Number of Sample Types",
y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C") +
# trend line and confidence interval
geom_abline(slope = coefficients(range_mod)[2],
intercept = coefficients(range_mod)[1]) +
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]),
color = "blue", fill = "blue", alpha = 0.2)
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
# points
geom_jitter(width = 0.2, height = 3) +
# scales and labels
scale_x_continuous(breaks = NULL) ) ) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) ) +
labs(color = "Latitude Range",
x = "Number of Sample Types",
y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C") +
# trend line and confidence interval
geom_abline(slope = coefficients(range_mod)[2],
intercept = coefficients(range_mod)[1]) +
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]),
color = "blue", fill = "blue", alpha = 0.2)
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
# points
geom_jitter(width = 0.2, height = 3) +
# scales and labels
#scale_x_continuous(breaks = NULL) ) ) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) ) +
labs(color = "Latitude Range",
x = "Number of Sample Types",
y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C") +
# trend line and confidence interval
geom_abline(slope = coefficients(range_mod)[2],
intercept = coefficients(range_mod)[1]) +
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]),
color = "blue", fill = "blue", alpha = 0.2)
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
# points
geom_jitter(width = 0.2, height = 3) +
# scales and labels
scale_x_continuous(breaks = NULL ) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) ) +
labs(color = "Latitude Range",
x = "Number of Sample Types",
y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C") +
# trend line and confidence interval
geom_abline(slope = coefficients(range_mod)[2],
intercept = coefficients(range_mod)[1]) +
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]),
color = "blue", fill = "blue", alpha = 0.2)
p
p <-ggplot(range_dat,  aes( x = group_count, range, color = range)) +
# points
geom_jitter(width = 0.2, height = 3) +
# scales and labels
theme(panel.grid.minor = element_blank())+
scale_x_continuous(breaks = seq_len( max( range_dat$group_count) ) ) +
labs(title = "Global Range vs. Distribution Across Sample Types ",
caption = paste( "P =", signif(range_anova$`Pr(>F)`[1], 3) ) ) +
labs(color = "Latitude Range",
x = "Number of Sample Types",
y = "Global Range in Latitude") +
scale_color_viridis_c(option = "C") +
# trend line and confidence interval
geom_abline(slope = coefficients(range_mod)[2],
intercept = coefficients(range_mod)[1]) +
geom_ribbon(aes(ymin = conf_int[,2], ymax = conf_int[,3]),
color = "blue", fill = "blue", alpha = 0.2)
p
# save plot
ggsave(filename = "sample_range_correlation.pdf", p)
